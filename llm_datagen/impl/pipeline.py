"""
Pipeline å¼•æ“å®ç°ï¼šå½»åº•è§£è€¦æ‰§è¡Œå¼•æ“ä¸ç®—å­ç¼–æ’ã€‚
"""
import threading
import signal
import time
import os
import logging
from abc import ABC, abstractmethod 
from typing import Any, List, Dict, Optional, Callable
from concurrent.futures import ThreadPoolExecutor, wait, FIRST_COMPLETED

# ------------------- å¹³å°çº§ Logger é…ç½® -------------------
_platform_logger = logging.getLogger("DataGen.Platform")
_platform_logger.setLevel(logging.INFO)
_platform_logger.propagate = False
if not _platform_logger.handlers:
    try:
        log_dir = os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(__file__))), "logs")
        os.makedirs(log_dir, exist_ok=True)
        log_file = os.path.join(log_dir, "platform.log")
        file_handler = logging.FileHandler(log_file, encoding='utf-8')
        file_handler.setLevel(logging.INFO)
        formatter = logging.Formatter("%(asctime)s [%(levelname)s] %(name)s: %(message)s", datefmt="%Y-%m-%d %H:%M:%S")
        file_handler.setFormatter(formatter)
        _platform_logger.addHandler(file_handler)
    except Exception:
        pass

from llm_datagen.core.pipeline import (
    IPipeline, ISequentialPipeline, IStreamingPipeline, IRecoverablePipeline,
    PipelineStatus
)
from llm_datagen.core.config import NodeConfig, WriterConfig
from llm_datagen.core.node import INode, IRecoverableNode, NodeStatus
from llm_datagen.core.operators import IOperator
from llm_datagen.core.hooks import (
    IPipelineHooks,
    DefaultPipelineHooks, 
    JsonFileCheckpointHooks,
    PipelineHooksAdapter
)
from llm_datagen.impl.node import NodeContextImpl, UnifiedNode, UnifiedOperatorNode, InputNode, OutputNode
from llm_datagen.impl.bus.bus import RecoverableStreamFactory, StreamFactory, get_protocol_extension

class PipelineContextImpl:
    """Pipeline æ‰§è¡Œä¸Šä¸‹æ–‡ï¼šç®¡ç†å…¨å±€ä¿¡å·"""
    def __init__(self, is_cancelled_func: Callable[[], bool]):
        self._is_cancelled = is_cancelled_func
    def is_cancelled(self) -> bool: return self._is_cancelled() if self._is_cancelled else False


# ==============================================================================
# 1. BasePipeline: æ ¸å¿ƒèº«ä»½ä¸çŠ¶æ€ management
# ==============================================================================

class BasePipeline(IRecoverablePipeline, ABC):
    """
    æœ€åŸºç¡€çš„ Pipeline æŠ½è±¡ç±»ã€‚
    æ‰¿æ‹…æ ‡è¯†ã€çŠ¶æ€ã€ç»“æœç›®å½•åŠåŸºç¡€ç”Ÿå‘½å‘¨æœŸç®¡ç†ã€‚
    """
    LOG_TAG = "Pipeline"

    def __init__(self, hooks: Optional[IPipelineHooks] = None, results_dir: str = "tmp/results", writer_config: Optional[WriterConfig] = None):
        self.results_dir = results_dir
        self.writer_config = writer_config or WriterConfig()
        self._hooks = self._init_hooks(hooks)
        self._hooks_adapter = PipelineHooksAdapter(self._hooks)
        
        self._pipeline_id = None
        self._status = PipelineStatus.PENDING.value
        self._nodes: List[INode] = []
        self._ctx: Optional[PipelineContextImpl] = None
        self._shutdown_event = threading.Event()
        self._start_time = 0
        self._end_time = 0
        self.config = {}

    def _init_hooks(self, hooks: Optional[IPipelineHooks]) -> IPipelineHooks:
        """æ™ºèƒ½åˆå§‹åŒ–æŒä¹…åŒ–é’©å­ï¼Œç¡®ä¿ Composite æ¨¡å¼ä¸‹ä¹Ÿèƒ½æ­£ç¡®æŒ‡å‘ results_dir"""
        from llm_datagen.core.hooks import CompositePipelineHooks
        def is_persistence(h): return isinstance(h, JsonFileCheckpointHooks)
        
        if hooks:
            # ç¡®ä¿ä¼ å…¥çš„è‡ªå®šä¹‰ Hooks ä¹ŸæŒ‡å‘åŒä¸€ä¸ª results_dir
            if hasattr(hooks, 'base_dir'): hooks.base_dir = self.results_dir
            elif hasattr(hooks, 'hooks'):
                for h in hooks.hooks:
                    if hasattr(h, 'base_dir'): h.base_dir = self.results_dir

            has_p = is_persistence(hooks) or (hasattr(hooks, 'hooks') and any(is_persistence(h) for h in hooks.hooks))
            if has_p:
                return hooks
            else:
                return CompositePipelineHooks([JsonFileCheckpointHooks(base_dir=self.results_dir), hooks])
        return JsonFileCheckpointHooks(base_dir=self.results_dir)

    @property
    def nodes(self) -> List[INode]: return self._nodes

    @nodes.setter
    def nodes(self, value: List[INode]): self._nodes = value

    @property
    def pipeline_id(self) -> str: return self._pipeline_id

    @property
    def status(self) -> str: return self._status

    @status.setter
    def status(self, value: str): self._status = value

    def get_duration(self) -> float:
        if self._start_time == 0: return 0
        return (self._end_time or time.time()) - self._start_time

    def cancel(self):
        if self._status == PipelineStatus.CANCELING.value or self._status == PipelineStatus.CANCELED.value:
            return
            
        self._status = PipelineStatus.CANCELING.value
        _platform_logger.warning(f"ğŸ›‘ Pipeline è¿›å…¥å–æ¶ˆä¸­çŠ¶æ€: {self.pipeline_id}")
        self._shutdown_event.set()
        for node in self._nodes:
            if hasattr(node, 'cancel'): node.cancel()

    def save_checkpoint(self, node: Optional[INode] = None):
        """ä¿å­˜è¿›åº¦ã€çŠ¶æ€ä»¥åŠæ¶ˆè€—ï¼šå§”æ‰˜ç»™ HooksAdapter"""
        if node:
            if isinstance(node, IRecoverableNode):
                cp = node.get_progress()
                if cp is not None:
                    # 1. åˆ¤å®šç‰©ç†çŠ¶æ€
                    node_status = "running"
                    if node.status == NodeStatus.COMPLETED: node_status = "completed"
                    elif node.status == NodeStatus.FAILED: node_status = "failed"
                    
                    # 2. æå–å½“å‰å·²å‘ç”Ÿçš„ Token æ¶ˆè€—
                    usage = {}
                    if hasattr(self._hooks, 'node_usages'):
                        usage = self._hooks.node_usages.get(node.node_id, {})
                    
                    # 3. å†™å…¥å…¨é‡æ£€æŸ¥ç‚¹
                    self._hooks_adapter.on_checkpoint(self.pipeline_id, node.node_id, {
                        "current": cp.get("current", 0) if isinstance(cp, dict) else cp,
                        "total": cp.get("total", 0) if isinstance(cp, dict) else 0,
                        "status": node_status,
                        "usage": usage # æ ¸å¿ƒï¼šToken æ¶ˆè€—ä¹Ÿä¸Šè½¦
                    })
        else:
            for n in self._nodes:
                self.save_checkpoint(n)

    def get_runtime(self) -> Dict[str, Any]:
        """è·å–è¿è¡Œæ—¶èº«ä»½å¿«ç…§ï¼ˆæœ€ç®€åŸºç¡€æ•°æ®ï¼‰"""
        return {
            "pipeline_id": self.pipeline_id,
            "status": self.status,
            "duration": self.get_duration(),
            "config": self.config,
            "writer_config": self.writer_config.to_dict()
        }

    def save_runtime(self, file_path: Optional[str] = None):
        """ä¿å­˜è¿è¡Œæ—¶è“å›¾åˆ°ç£ç›˜"""
        import json
        path = file_path or os.path.join(self.results_dir, self.pipeline_id, "runtime.json")
        os.makedirs(os.path.dirname(os.path.abspath(path)), exist_ok=True)
        with open(path, 'w', encoding='utf-8') as f:
            json.dump(self.get_runtime(), f, indent=2, ensure_ascii=False)
        
        tag = getattr(self, "LOG_TAG", "Pipeline")
        _platform_logger.info(f"ğŸ’¾ [{tag}] è¿è¡Œæ—¶è“å›¾å·²ä¿å­˜: {path}")

    @abstractmethod
    def resume_from_runtime(self, runtime_data: Dict[str, Any]):
        """å­ç±»å¿…é¡»å®ç°æ¢å¤é€»è¾‘"""
        pass

    def resume(self, pipeline_id: str):
        """è‡ªåŠ¨åŒ–æ¢å¤ï¼šæ ¹æ® Pipeline ID è‡ªåŠ¨ä»ç£ç›˜åŠ è½½è“å›¾å¹¶å®Œæˆå¤æ´»"""
        import json
        runtime_path = os.path.join(self.results_dir, pipeline_id, "runtime.json")
        if not os.path.exists(runtime_path):
            raise FileNotFoundError(f"æ— æ³•æ‰¾åˆ° Pipeline '{pipeline_id}' çš„è“å›¾æ–‡ä»¶: {runtime_path}")
            
        with open(runtime_path, "r", encoding="utf-8") as f:
            runtime_data = json.load(f)
            
        return self.resume_from_runtime(runtime_data)

    def resume_from_file(self, file_path: str):
        import json
        if not os.path.exists(file_path):
            raise FileNotFoundError(f"Checkpoint file not found: {file_path}")
        with open(file_path, 'r', encoding='utf-8') as f:
            runtime_data = json.load(f)
        return self.resume_from_runtime(runtime_data)


# ==============================================================================
# 2. NodePipeline: èŠ‚ç‚¹é©±åŠ¨å±‚ (åªçŸ¥é“ Nodeï¼Œä¸çŸ¥é“ Operator)
# ==============================================================================

class NodePipeline(BasePipeline):
    """
    èŠ‚ç‚¹æ‰§è¡ŒåŸºç±»ï¼šçº¯ç²¹çš„æ‰§è¡Œå¼•æ“ã€‚
    ç®¡ç† Node åˆ—è¡¨çš„å£°æ˜å‘¨æœŸï¼ˆopen/closeï¼‰ã€ä¿¡å·å¤„ç†åŠä½ç‚¹æ¢å¤ã€‚
    """
    def open(self):
        self._start_time = time.time()
        
        # æ ¸å¿ƒä¿®å¤ï¼šå¦‚æœå·²ç»åœ¨æ¢å¤ä¸­ï¼Œä¿æŒ RESUMING çŠ¶æ€ï¼Œç›´åˆ°çœŸæ­£è¿è¡Œ
        if self._status != PipelineStatus.RESUMING.value:
            self._status = PipelineStatus.RUNNING.value
            
        _platform_logger.info(f"ğŸš€ [Engine] Pipeline å¯åŠ¨: {self.pipeline_id} (Mode={'Resume' if self._status == PipelineStatus.RESUMING.value else 'New'})")
        
        self._setup_signal_handlers()
        
        if not self._ctx:
            self._ctx = PipelineContextImpl(lambda: self._shutdown_event.is_set())

        self._hooks_adapter.on_pipeline_start(self.pipeline_id, self.config)
        
        # ä¸ºæ¯ä¸ªç‰©ç†èŠ‚ç‚¹æ³¨å…¥ Context
        for node in self._nodes:
            # æ³¨å…¥å…¨å±€å†™å…¥é…ç½®
            if hasattr(node, "set_writer_config"):
                node.set_writer_config(self.writer_config)
            
            node_ctx = self._create_node_context(node)
            if hasattr(node, "set_context"): 
                node.set_context(node_ctx)

    def _setup_signal_handlers(self):
        def handler(sig, frame): self.cancel()
        if threading.current_thread() is threading.main_thread():
            try: 
                signal.signal(signal.SIGINT, handler)
                signal.signal(signal.SIGTERM, handler)
            except: pass

    def close(self, success: bool, error: Exception = None):
        self._end_time = time.time()
        self._status = PipelineStatus.COMPLETED.value if success else PipelineStatus.FAILED.value
        
        status_str = "SUCCESS" if success else f"FAILED ({error})"
        _platform_logger.info(f"ğŸ [Engine] Pipeline ç»“æŸ: {self.pipeline_id} | Status: {status_str} | Duration: {self.get_duration():.2f}s")
        
        self._hooks_adapter.on_pipeline_end(self.pipeline_id, success, error)

    def resume_from_runtime(self, runtime_data: Dict[str, Any]):
        """æ‰§è¡Œå¼•æ“å±‚çš„æ¢å¤ï¼šä»…è´Ÿè´£ Hooks çŠ¶æ€å’Œç‰©ç†èŠ‚ç‚¹çš„ä½ç‚¹åŒæ­¥"""
        self._pipeline_id = runtime_data.get("pipeline_id")
        self._status = PipelineStatus.RESUMING.value 
        
        # 0. æ¢å¤å†™å…¥ç­–ç•¥
        if "writer_config" in runtime_data:
            from llm_datagen.core.config import WriterConfig
            self.writer_config = WriterConfig(**runtime_data["writer_config"])
            
        # 1. æ¢å¤ Hooks ä¸šåŠ¡çŠ¶æ€ (å¦‚æœ‰)
        if "hook_state" in runtime_data and runtime_data["hook_state"] and hasattr(self._hooks, "load_state_data"):
            self._hooks.load_state_data(runtime_data["hook_state"])
            
        # 2. æ ¸å¿ƒï¼šåŠ è½½ç£ç›˜æŒä¹…åŒ–ä½ç‚¹ (è¿™æ˜¯æœ€å®æ—¶çš„çœŸç†æ¥æº)
        if hasattr(self._hooks, "load_state"): 
            self._hooks.load_state(self.pipeline_id, self.config)

        # 3. éå†å½“å‰ç‰©ç†èŠ‚ç‚¹å¹¶æ³¨å…¥æ¢å¤çŠ¶æ€
        for node in self._nodes:
            # è·å–è¯¥èŠ‚ç‚¹çš„å®æ—¶æ£€æŸ¥ç‚¹ (è¿™æ˜¯ç£ç›˜ä¸Šæœ€æ–°çš„çœŸç›¸)
            cp = None
            if hasattr(self._hooks, 'get_checkpoint'):
                cp = self._hooks.get_checkpoint(node.node_id)
            
            # å‡†å¤‡èŠ‚ç‚¹çš„æ¢å¤å¿«ç…§
            node_rt = next((n for n in runtime_data.get("nodes", []) if n.get("node_id") == node.node_id), {})
            
            # èåˆ Checkpointï¼šå¦‚æœç£ç›˜æœ‰æ›´æ–°çš„è¿›åº¦ï¼Œè¦†ç›–å¿«ç…§ä¸­çš„æ—§å€¼
            if cp and isinstance(cp, dict):
                curr = cp.get("current", 0)
                total = cp.get("total", 0)
                status = cp.get("status", "running")
                
                # æ˜¾å¼æ³¨å…¥çŠ¶æ€ç»™å¿«ç…§å¯¹è±¡
                node_rt["progress"] = {"current": curr, "total": total}
                
                # æ ¸å¿ƒä¿®å¤ï¼šä¸å†é€šè¿‡è¿›åº¦çŒœå®ŒæˆçŠ¶æ€ï¼Œåªç›¸ä¿¡æ˜¾å¼çš„ status æ ‡è®°
                # å°¤å…¶æ˜¯åœ¨æµå¼æ¨¡å¼ä¸‹ï¼Œcurr >= total åœ¨å´©æºƒæ—¶å¾€å¾€æ˜¯æˆç«‹çš„å‡è±¡
                if status == "completed":
                    node_rt["status"] = NodeStatus.COMPLETED
                elif status == "failed":
                    node_rt["status"] = NodeStatus.FAILED
                else:
                    node_rt["status"] = NodeStatus.RESUMING
            
            # æ³¨å…¥æ¢å¤
            node.resume_from_runtime(runtime_data=node_rt)
            
            # æ ¸å¿ƒæ”¹è¿›ï¼šå¯¹äºå·²å®Œæˆçš„èŠ‚ç‚¹ï¼Œç¡®ä¿å…¶ç‰©ç†å°æ¡å­˜åœ¨ï¼Œé˜²æ­¢ä¸‹æ¸¸é˜»å¡
            if node.status == NodeStatus.COMPLETED:
                if hasattr(node, "output_stream") and node.output_stream:
                    if hasattr(node.output_stream, "seal"):
                        node.output_stream.seal()
            
            _platform_logger.info(f"ğŸ§¬ [Engine] å·²ä¸ºèŠ‚ç‚¹ {node.node_id} æ³¨å…¥æ¢å¤ä½ç‚¹: {cp}")
            
        return self

    def _create_node_context(self, node: INode):
        pipeline_id = self.pipeline_id
        
        def _on_usage(m):
            # è‡ªåŠ¨å—…æ¢æ ¼å¼å¹¶è½¬å‘ï¼Œç¡®ä¿ Token ç»Ÿè®¡æ­£ç¡®
            provider = m.get("provider", "unknown")
            model = m.get("model", "unknown")
            # è¿‡æ»¤æ‰éæ•°å€¼å­—æ®µï¼Œåªä¼ é€’çœŸæ­£çš„ metrics æŒ‡æ ‡
            numeric_metrics = {k: v for k, v in m.items() if isinstance(v, (int, float)) and k not in ["provider", "model"]}
            self._hooks_adapter.on_usage(pipeline_id, node.node_id, provider, model, numeric_metrics)

        return NodeContextImpl(
            node_id=node.node_id, 
            context_id=pipeline_id, 
            on_progress=lambda curr, total, meta, nid=node.node_id: self._hooks_adapter.on_node_progress(pipeline_id, nid, curr, total, meta),
            on_usage=_on_usage,
            on_log=lambda msg, lv, nid=node.node_id: self._hooks_adapter.on_node_log(pipeline_id, nid, msg, lv),
            on_error=lambda e, items, nid=node.node_id: self._hooks_adapter.on_node_error(pipeline_id, nid, e, items),
            is_cancelled_func=self._ctx.is_cancelled,
            # æ ¸å¿ƒæ”¹è¿›ï¼šå…è®¸ Node ä¸»åŠ¨è§¦å‘ Pipeline å­˜ç›˜
            save_checkpoint_func=lambda nid=node.node_id: self.save_checkpoint(node)
        )


class SequentialPipeline(NodePipeline, ISequentialPipeline):
    """é¡ºåºæ‰§è¡Œå¼•æ“ï¼šé€ä¸ªè¿è¡ŒèŠ‚ç‚¹"""
    def run(self):
        self._shutdown_event.clear()
        self.open()
        
        _platform_logger.info(f"ğŸš€ [Sequential] Pipeline å¯åŠ¨: {self.pipeline_id}")
        
        success = True; error = None
        try:
            for node in self.nodes:
                if self._shutdown_event.is_set(): break
                
                # æ ¸å¿ƒæ”¹è¿›ï¼šè·³è¿‡å·²å®Œæˆçš„èŠ‚ç‚¹ (æ¢å¤æ¨¡å¼çš„å…³é”®)
                if node.status == NodeStatus.COMPLETED:
                    _platform_logger.info(f"â­ï¸  èŠ‚ç‚¹ {node.node_id} å·²åœ¨å†å²è®°å½•ä¸­å®Œæˆï¼Œè·³è¿‡")
                    continue

                print(f"\nğŸ¬ æ­£åœ¨è¿è¡ŒèŠ‚ç‚¹: {node.node_id}")
                try:
                    self._hooks_adapter.on_node_start(self.pipeline_id, node.node_id, {})
                    node.run()
                    # è¿è¡ŒæˆåŠŸï¼Œç«‹å³æ˜¾å¼æ›´æ–°å¹¶ä¿å­˜æ£€æŸ¥ç‚¹
                    node.status = NodeStatus.COMPLETED
                    self.save_checkpoint(node)
                    self._hooks_adapter.on_node_finish(self.pipeline_id, node.node_id)
                except Exception as e:
                    # è¿è¡Œå¤±è´¥ï¼Œç«‹å³æ˜¾å¼æ›´æ–°å¹¶ä¿å­˜æ£€æŸ¥ç‚¹
                    node.status = NodeStatus.FAILED
                    self.save_checkpoint(node)
                    self._hooks_adapter.on_node_error(self.pipeline_id, node.node_id, e, [])
                    raise
                finally: node.close()
        except Exception as e:
            success = False; error = e; raise
        finally: self.close(success, error)


class StreamingPipeline(NodePipeline, IStreamingPipeline):
    """æµå¼æ‰§è¡Œå¼•æ“ï¼šå¹¶è¡Œè¿è¡ŒèŠ‚ç‚¹"""
    def run(self):
        self._shutdown_event.clear()
        self.open()
        
        print(f"\nğŸš€ [Streaming] æ­£åœ¨å¹¶è¡Œå¯åŠ¨æ‰€æœ‰èŠ‚ç‚¹...")
        _platform_logger.info(f"ğŸš€ [Streaming] Pipeline å¯åŠ¨: {self.pipeline_id}")
            
        success = True; error = None
        try:
            # æ ¸å¿ƒä¿®å¤ï¼šåŒæ­¥é¢„çƒ­
            # åœ¨å¯åŠ¨å¹¶è¡Œçº¿ç¨‹æ± ä¹‹å‰ï¼Œå…ˆåŒæ­¥æ‰§è¡Œæ‰€æœ‰éå®ŒæˆèŠ‚ç‚¹çš„ open()
            # ç¡®ä¿ä¸Šæ¸¸çš„ unseal (æ’•å°æ¡) åŠ¨ä½œç»å¯¹é¢†å…ˆäºä¸‹æ¸¸ Reader å¯¹ EOF çš„åˆ¤å®š
            for node in self.nodes:
                if node.status != NodeStatus.COMPLETED:
                    # é¢„å…ˆæ³¨å…¥ Context å¹¶æ‰§è¡Œ open
                    node_ctx = self._create_node_context(node)
                    node.open(ctx=node_ctx)

            for node in self.nodes:
                if node.status == NodeStatus.COMPLETED:
                    _platform_logger.info(f"â­ï¸  [Streaming] èŠ‚ç‚¹ {node.node_id} å·²å®Œæˆï¼Œè·³è¿‡è°ƒåº¦")
                    continue
                self._hooks_adapter.on_node_start(self.pipeline_id, node.node_id, {})

            with ThreadPoolExecutor(max_workers=len(self.nodes)) as executor:
                futures = {executor.submit(node.run): node for node in self.nodes if node.status != NodeStatus.COMPLETED}
                pending = set(futures.keys())
                while pending:
                    if self._shutdown_event.is_set():
                        for f in pending: f.cancel()
                        break
                    done, pending = wait(pending, timeout=1.0, return_when=FIRST_COMPLETED)
                    for f in done:
                        node = futures[f]
                        try:
                            f.result()
                            # åªæœ‰åœ¨éå–æ¶ˆçŠ¶æ€ä¸‹æ­£å¸¸ç»“æŸï¼Œæ‰æ ‡è®°ä¸ºå·²å®Œæˆ
                            if not self._shutdown_event.is_set():
                                node.status = NodeStatus.COMPLETED
                                self.save_checkpoint(node)
                                self._hooks_adapter.on_node_finish(self.pipeline_id, node.node_id)
                            node.close()
                        except Exception as e:
                            _platform_logger.error(f"ğŸš¨ [Streaming] èŠ‚ç‚¹ {node.node_id} å¼‚å¸¸ï¼Œæ­£åœ¨å–æ¶ˆ Pipeline...")
                            node.status = NodeStatus.FAILED
                            self.save_checkpoint(node)
                            self._hooks_adapter.on_node_error(self.pipeline_id, node.node_id, e, [])
                            # æ ¸å¿ƒæ”¹è¿›ï¼šè¿›å…¥å–æ¶ˆæµç¨‹ï¼Œä¸ç«‹å³é€€å‡ºï¼Œç­‰å¾…å…¶ä»–çº¿ç¨‹
                            self.cancel()
                            success = False
                            error = e
                            break
                
                # å¦‚æœå¤±è´¥ï¼Œç­‰å¾…å‰©ä½™ä»»åŠ¡æ”¶å°¾
                if not success:
                    wait(pending, timeout=5.0)
        except Exception as e:
            success = False; error = e; raise
        finally:
            if self._status == PipelineStatus.CANCELING.value:
                self._status = PipelineStatus.CANCELED.value
            self.close(success, error)


class UnifiedNodePipeline(BasePipeline):
    """
    ç»Ÿä¸€èŠ‚ç‚¹ Masterï¼š
    1. ç›´æ¥æ¥æ”¶ç‰©ç†èŠ‚ç‚¹åˆ—è¡¨ (INode)
    2. è´Ÿè´£æ‰§è¡Œå¼•æ“é€‰å‹ (Streaming vs Sequential)
    3. ç»´æŒç‰©ç† Master çº§å‚æ•° (streaming, batch_size, parallel_size)
    """
    LOG_TAG = "Unified"

    def __init__(self, 
                 nodes: List[INode] = None, 
                 streaming: bool = False,
                 batch_size: int = 1,
                 parallel_size: int = 1,
                 hooks: Optional[IPipelineHooks] = None,
                 results_dir: str = "tmp/results",
                 writer_config: Optional[WriterConfig] = None):
        super().__init__(hooks=hooks, results_dir=results_dir, writer_config=writer_config)
        self._nodes = nodes or []
        self._streaming = streaming
        self._batch_size = batch_size
        self._parallel_size = parallel_size
        self._impl: Optional[NodePipeline] = None

    def create(self, 
               pipeline_id: str = None,
               streaming: Optional[bool] = None):
        """ç‰©ç†åˆ›å»ºå…¥å£ï¼šé€‰å‹å¹¶ç»‘å®šå¼•æ“"""
        self._pipeline_id = pipeline_id or f"pipe_{int(time.time() * 1000)}"
        if streaming is not None:
            self._streaming = streaming
        
        # é€‰å‹å¼•æ“å®ç°
        engine_cls = StreamingPipeline if self._streaming else SequentialPipeline
        self._impl = engine_cls(hooks=self._hooks, results_dir=self.results_dir, writer_config=self.writer_config)
        
        # åŒæ­¥çŠ¶æ€ç»™å®ç°å±‚
        self._impl._pipeline_id = self.pipeline_id
        self._impl.nodes = self._nodes
        self._impl.config = self.config
        
        # ç‰©ç†åˆ›å»ºå®Œæˆåç«‹å³æŒä¹…åŒ–è“å›¾
        self.save_runtime()

    def get_runtime(self) -> Dict[str, Any]:
        """èåˆ Master é…ç½®ä¸ç‰©ç†è¿›åº¦"""
        rt = super().get_runtime()
        rt.update({
            "streaming": self._streaming,
            "batch_size": self._batch_size,
            "parallel_size": self._parallel_size,
            "nodes": [node.get_runtime() for node in self.nodes] if self.nodes else []
        })
        return rt

    def run(self):
        if not self._impl: raise RuntimeError("Pipeline not created or resumed.")
        return self._impl.run()

    def cancel(self):
        """ä¿¡å·ä¸‹å‘"""
        if self._impl: self._impl.cancel()
        else: super().cancel()

    def resume_from_runtime(self, runtime_data: Dict[str, Any]):
        """Master çº§æ¢å¤ï¼šæ¢å¤é…ç½® -> é€‰å‹å¼•æ“ -> åŒæ­¥è¿›åº¦"""
        self._pipeline_id = runtime_data["pipeline_id"]
        self._streaming = runtime_data.get("streaming", False)
        self._batch_size = runtime_data.get("batch_size", 1)
        self._parallel_size = runtime_data.get("parallel_size", 1)
        
        # é€‰å‹å¼•æ“
        engine_cls = StreamingPipeline if self._streaming else SequentialPipeline
        self._impl = engine_cls(hooks=self._hooks, results_dir=self.results_dir, writer_config=self.writer_config)
        self._impl._pipeline_id = self.pipeline_id
        self._impl.nodes = self._nodes
        
        # å¼•æ“å±‚æ¢å¤å®æ—¶è¿›åº¦
        self._impl.resume_from_runtime(runtime_data)
        return self

    # --- å±æ€§ä»£ç† ---
    @property
    def status(self) -> str: return self._impl.status if self._impl else super().status
    @property
    def nodes(self) -> List[INode]: return self._impl.nodes if self._impl else self._nodes
    def get_duration(self) -> float: return self._impl.get_duration() if self._impl else super().get_duration()

    def __getattr__(self, name): 
        if self._impl and hasattr(self._impl, name): return getattr(self._impl, name)
        raise AttributeError(f"'{self.__class__.__name__}' object has no attribute '{name}'")


class UnifiedOperatorPipeline(UnifiedNodePipeline):
    """
    ç»Ÿä¸€ç®—å­ Masterï¼š
    1. è´Ÿè´£é€»è¾‘ç®—å­ç¼–æ’ (Operators -> Nodes)
    2. ç»´æŒç®—å­ Master çº§å‚æ•° (input_uri, output_uri, ...)
    """
    LOG_TAG = "Unified"

    def __init__(self, 
                 operators: List[IOperator] = None, 
                 input_uri: str = None,
                 output_uri: str = None,
                 batch_size: int = 1,
                 parallel_size: int = 1,
                 streaming: bool = False,
                 protocol_prefix: str = "node_",
                 base_path: str = "tmp",
                 default_protocol: str = "jsonl://",
                 bus_factory: RecoverableStreamFactory = None,
                 hooks: Optional[IPipelineHooks] = None,
                 results_dir: str = "tmp/results",
                 writer_config: Optional[WriterConfig] = None):
        # å°†ç‰©ç†å‚æ•°ä¼ ç»™ UnifiedNodePipeline
        super().__init__(nodes=[], 
                         streaming=streaming, 
                         batch_size=batch_size, 
                         parallel_size=parallel_size, 
                         hooks=hooks, 
                         results_dir=results_dir,
                         writer_config=writer_config)
        self._operators = operators or []
        self._bus_factory = bus_factory or RecoverableStreamFactory
        
        # ç¼–æ’ç‰¹æœ‰å‚æ•°
        self._input_uri = input_uri
        self._output_uri = output_uri
        self._protocol_prefix = protocol_prefix
        self._base_path = base_path
        self._default_protocol = default_protocol

    def create(self, 
               pipeline_id: str = None,
               input_uri: Optional[str] = None, 
               output_uri: Optional[str] = None, 
               streaming: Optional[bool] = None,
               batch_size: Optional[int] = None,
               parallel_size: Optional[int] = None,
               protocol_prefix: Optional[str] = None,
               base_path: Optional[str] = None,
               default_protocol: Optional[str] = None,
               node_configs: Optional[List[NodeConfig]] = None):
        """ç®—å­ç¼–æ’å…¥å£ï¼šé€»è¾‘æ˜ å°„ + å¼•æ“é€‰å‹"""
        self._pipeline_id = pipeline_id or f"pipe_{int(time.time() * 1000)}"
        
        # å…è®¸é€šè¿‡ create è¦†ç›–é…ç½®
        if input_uri: self._input_uri = input_uri
        if output_uri: self._output_uri = output_uri
        if batch_size: self._batch_size = batch_size
        if parallel_size: self._parallel_size = parallel_size
        if protocol_prefix is not None: self._protocol_prefix = protocol_prefix
        if base_path is not None: self._base_path = base_path
        if default_protocol: self._default_protocol = default_protocol

        if not self._input_uri or not self._output_uri:
            raise ValueError(f"Pipeline '{self._pipeline_id}' requires both 'input_uri' and 'output_uri'.")
            
        _platform_logger.info(f"ğŸ—ï¸  æ­£åœ¨ç¼–æ’é€»è¾‘è“å›¾: {self._pipeline_id}")
        
        plans = self._plan_topology(node_configs)
        self._weld_topology(plans)
        self._nodes = self._materialize_topology(plans)
        self._clear_streams_if_needed()

        # 2. è°ƒç”¨çˆ¶ç±» (UnifiedNodePipeline) å®Œæˆå¼•æ“é€‰å‹ä¸æŒä¹…åŒ–
        super().create(pipeline_id=self._pipeline_id, streaming=streaming)

    def get_runtime(self) -> Dict[str, Any]:
        """æ‰©å±•ç®—å­ç¼–æ’ç‰¹æœ‰å‚æ•°"""
        rt = super().get_runtime() # å·²åŒ…å« streaming, batch_size, parallel_size
        rt.update({
            "input_uri": self._input_uri,
            "output_uri": self._output_uri,
            "protocol_prefix": self._protocol_prefix,
            "base_path": self._base_path,
            "default_protocol": self._default_protocol
        })
        return rt

    def resume_from_runtime(self, runtime_data: Dict[str, Any]):
        """æ¢å¤ç¼–æ’å‚æ•° -> é‡å»ºè“å›¾ -> æ¢å¤å¼•æ“è¿›åº¦"""
        self._input_uri = runtime_data.get("input_uri")
        self._output_uri = runtime_data.get("output_uri")
        self._protocol_prefix = runtime_data.get("protocol_prefix", "")
        self._base_path = runtime_data.get("base_path", "")
        self._default_protocol = runtime_data.get("default_protocol", "jsonl://")
        
        # é‡å»ºç‰©ç†èŠ‚ç‚¹
        self._nodes = self._reconstruct_topology(runtime_data)
        
        # æ¢å¤ç‰©ç†é…ç½®ä¸å¼•æ“
        super().resume_from_runtime(runtime_data)
        return self

    # --- é€»è¾‘ç¼–æ’å·¥å…·æ–¹æ³• (ä¿ç•™åŸ BaseOperatorPipeline çš„ç²¾å) ---
    def _plan_topology(self, node_configs: Optional[List[NodeConfig]] = None) -> List[Dict]:
        """æ„å»ºé€»è¾‘è“å›¾ï¼šå°†ç®—å­å’Œ I/O æ¬è¿å·¥ç»Ÿä¸€"""
        plans = []
        plans.append({"node_id": "input", "type": "io_in", "config": {"input_uri": self._input_uri, "batch_size": self._batch_size, "parallel_size": self._parallel_size, "protocol_prefix": self._protocol_prefix, "base_path": self._base_path}})
        for i, op in enumerate(self._operators):
            raw_conf = node_configs[i] if (node_configs and i < len(node_configs)) else {}
            conf_dict = raw_conf.to_dict() if isinstance(raw_conf, NodeConfig) else raw_conf
            full_conf = {"batch_size": self._batch_size, "parallel_size": self._parallel_size, "protocol_prefix": self._protocol_prefix, "base_path": self._base_path}
            full_conf.update(conf_dict)
            plans.append({"node_id": f"node_{i}", "type": "functional", "operator": op, "config": full_conf})
        plans.append({"node_id": "output", "type": "io_out", "config": {"output_uri": self._output_uri, "batch_size": self._batch_size, "parallel_size": self._parallel_size, "protocol_prefix": self._protocol_prefix, "base_path": self._base_path}})
        return plans

    def _weld_topology(self, plans: List[Dict]):
        for i in range(len(plans)):
            conf = plans[i]["config"]
            if i > 0:
                prev_conf = plans[i-1]["config"]
                if conf.get("input_uri") and not prev_conf.get("output_uri"): prev_conf["output_uri"] = conf["input_uri"]
                elif not conf.get("input_uri") and prev_conf.get("output_uri"): conf["input_uri"] = prev_conf["output_uri"]
                elif conf.get("input_uri") and prev_conf.get("output_uri") and conf["input_uri"] != prev_conf["output_uri"]:
                    raise ValueError(f"Topology Error: URI mismatch between {plans[i-1]['node_id']} and {plans[i]['node_id']}")
        for i, plan in enumerate(plans):
            conf = plan["config"]
            if not conf.get("output_uri") and i < len(plans) - 1:
                proto = self._default_protocol; ext = get_protocol_extension(proto)
                conf["output_uri"] = f"{proto}{self._pipeline_id.strip('/')}/{plan['node_id']}{ext}"
                plans[i+1]["config"]["input_uri"] = conf["output_uri"]

    def _materialize_topology(self, plans: List[Dict]) -> List[INode]:
        final_nodes = []
        for plan in plans:
            conf = plan["config"]; nid = plan["node_id"]; ntype = plan["type"]
            in_uri = conf.get("input_uri"); out_uri = conf.get("output_uri")
            in_prefix = "" if in_uri == self._input_uri else (conf.get("protocol_prefix") or "")
            out_prefix = "" if out_uri == self._output_uri else (conf.get("protocol_prefix") or "")
            in_base = "" if in_uri == self._input_uri else (conf.get("base_path") or "")
            out_base = "" if out_uri == self._output_uri else (conf.get("base_path") or "")
            in_s = self._bus_factory.create(in_uri, protocol_prefix=in_prefix, base_path=in_base) if in_uri else StreamFactory.create(None)
            out_s = self._bus_factory.create(out_uri, protocol_prefix=out_prefix, base_path=out_base) if out_uri else StreamFactory.create(None)
            if ntype == "io_in": node = InputNode(input_uri=in_uri, output_uri=out_uri, batch_size=conf.get("batch_size", 1), parallel_size=conf.get("parallel_size", 1), protocol_prefix=conf.get("protocol_prefix", ""), base_path=conf.get("base_path", ""))
            elif ntype == "io_out": node = OutputNode(input_uri=in_uri, output_uri=out_uri, batch_size=conf.get("batch_size", 1), parallel_size=conf.get("parallel_size", 1), protocol_prefix=conf.get("protocol_prefix", ""), base_path=conf.get("base_path", ""))
            else: node = UnifiedOperatorNode(operator=plan["operator"], node_id=nid, input_uri=in_uri, output_uri=out_uri, batch_size=conf.get("batch_size", 1), parallel_size=conf.get("parallel_size", 1), protocol_prefix=conf.get("protocol_prefix", ""), base_path=conf.get("base_path", ""))
            node.bind_io(in_s, out_s); final_nodes.append(node)
        return final_nodes

    def _reconstruct_topology(self, runtime_data: Dict[str, Any]) -> List[INode]:
        node_states = runtime_data.get("nodes", []); plans = []; func_idx = 0
        for ns in node_states:
            nid = ns["node_id"]
            conf = {"batch_size": ns.get("batch_size", 1), "parallel_size": ns.get("parallel_size", 1), "input_uri": ns.get("input_uri"), "output_uri": ns.get("output_uri"), "protocol_prefix": ns.get("protocol_prefix", ""), "base_path": ns.get("base_path", "")}
            if nid == "input": plan = {"node_id": nid, "type": "io_in", "config": conf}
            elif nid == "output": plan = {"node_id": nid, "type": "io_out", "config": conf}
            else:
                op = self._operators[func_idx] if func_idx < len(self._operators) else None
                plan = {"node_id": nid, "type": "functional", "operator": op, "config": conf}
                func_idx += 1
            plans.append(plan)
        return self._materialize_topology(plans)

    def _clear_streams_if_needed(self):
        source = self._nodes[0].input_stream if self._nodes else None
        for n in self._nodes:
            if hasattr(n, 'output_stream') and n.output_stream and n.output_stream != source: n.output_stream.clear_data()
        res_dir = os.path.join(self.results_dir, self.pipeline_id)
        for target in ["checkpoint.json", "report.json", "runtime.json"]:
            path = os.path.join(res_dir, target)
            if os.path.exists(path):
                try: os.remove(path); _platform_logger.info(f"  ğŸ—‘ï¸  å·²ç‰©ç†åˆ é™¤æ—§æ–‡ä»¶: {target}")
                except Exception as e: _platform_logger.warning(f"  âš ï¸  åˆ é™¤ {target} å¤±è´¥: {e}")


# åˆ«åï¼Œå‘åå…¼å®¹
UnifiedPipeline = UnifiedOperatorPipeline
